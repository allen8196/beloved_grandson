import hashlib
import os
from typing import Optional

# ç¦ç”¨ CrewAI é™æ¸¬åŠŸèƒ½ï¼ˆé¿å…é€£æ¥éŒ¯èª¤ï¼‰
os.environ["OTEL_SDK_DISABLED"] = "true"
os.environ["CREWAI_TELEMETRY_OPT_OUT"] = "true"

from crewai import Crew, Task
from openai import OpenAI

from .HealthBot.agent import (
    build_prompt_from_redis,
    create_guardrail_agent,
    create_health_companion,
    finalize_session,
)
from .toolkits.redis_store import (
    acquire_audio_lock,
    append_round,
    get_audio_result,
    make_request_id,
    peek_next_n,
    read_and_clear_audio_segments,
    release_audio_lock,
    set_audio_result,
    set_state_if,
    try_register_request,
)
from .toolkits.tools import (
    ModelGuardrailTool,
    SearchMilvusTool,
    summarize_chunk_and_commit,
)

SUMMARY_CHUNK_SIZE = int(os.getenv("SUMMARY_CHUNK_SIZE", 5))


class AgentManager:
    def __init__(self):
        self.guardrail_agent = create_guardrail_agent()
        self.health_agent_cache = {}

    def get_guardrail(self):
        return self.guardrail_agent

    def get_health_agent(self, user_id: str):
        if user_id not in self.health_agent_cache:
            self.health_agent_cache[user_id] = create_health_companion(user_id)
        return self.health_agent_cache[user_id]

    def release_health_agent(self, user_id: str):
        if user_id in self.health_agent_cache:
            del self.health_agent_cache[user_id]


def log_session(user_id: str, query: str, reply: str, request_id: Optional[str] = None):
    rid = request_id or make_request_id(user_id, query)
    if not try_register_request(user_id, rid):
        # å»é‡ï¼Œè·³éé‡è¤‡è«‹æ±‚
        return
    append_round(user_id, {"input": query, "output": reply, "rid": rid})
    # å˜—è©¦æŠ“ä¸‹ä¸€æ®µ 5 è¼ªï¼ˆä¸è¶³æœƒå›ç©ºï¼‰â†’ LLM æ‘˜è¦ â†’ CAS æäº¤
    start, chunk = peek_next_n(user_id, SUMMARY_CHUNK_SIZE)
    if start is not None and chunk:
        summarize_chunk_and_commit(user_id, start_round=start, history_chunk=chunk)


def handle_user_message(
    agent_manager: AgentManager,
    user_id: str,
    query: str,
    audio_id: Optional[str] = None,
    is_final: bool = True,
) -> str:
    # 0) çµ±ä¸€éŸ³æª” IDï¼ˆæ²’å¸¶å°±ç”¨æ–‡å­— hash ç•¶è‡¨æ™‚ IDï¼Œå‘å¾Œç›¸å®¹ï¼‰
    audio_id = audio_id or hashlib.sha1(query.encode("utf-8")).hexdigest()[:16]

    # 1) é finalï¼šä¸è§¸ç™¼ä»»ä½• LLM/RAG/é€šå ±ï¼Œåªç·©è¡ç‰‡æ®µ
    if not is_final:
        from .toolkits.redis_store import append_audio_segment  # å»¶é²è¼‰å…¥é¿å…å¾ªç’°

        append_audio_segment(user_id, audio_id, query)
        return "ğŸ‘Œ å·²æ”¶åˆ°èªéŸ³ç‰‡æ®µ"

    # 2) éŸ³æª”ç´šé–ï¼šä¸€æ¬¡ä¸”åªä¸€æ¬¡è™•ç†åŒä¸€æ®µéŸ³æª”
    lock_id = f"{user_id}#audio:{audio_id}"
    # ä½¿ç”¨ç¨ç«‹çš„è¼•é‡é–ï¼Œé¿å…èˆ‡å…¶ä»– session state è¡çª
    # P0-1: å¢åŠ  TTL åˆ° 180 ç§’ï¼Œé¿å…é•·èªéŸ³è™•ç†æ™‚é–éæœŸ
    if not acquire_audio_lock(lock_id, ttl_sec=180):
        cached = get_audio_result(user_id, audio_id)
        return cached or "æˆ‘æ­£åœ¨è™•ç†ä½ çš„èªéŸ³ï¼Œè«‹ç¨ç­‰ä¸€ä¸‹å–”ã€‚"

    try:
        # 3) åˆä½µä¹‹å‰ç·©è¡çš„ partial â†’ æœ€çµ‚è¦è™•ç†çš„å…¨æ–‡
        head = read_and_clear_audio_segments(user_id, audio_id)
        full_text = (head + " " + query).strip() if head else query

        # 4) å…ˆ guardrailï¼Œå† health agent
        os.environ["CURRENT_USER_ID"] = user_id

        # å„ªå…ˆç”¨ CrewAIï¼›å¤±æ•—å‰‡ fallback è‡ªè¡Œåˆ¤æ–·
        try:
            guard = agent_manager.get_guardrail()
            guard_task = Task(
                description=(
                    f"åˆ¤æ–·æ˜¯å¦éœ€è¦æ””æˆªï¼šã€Œ{full_text}ã€ã€‚"
                    "å‹™å¿…ä½¿ç”¨ model_guardrail å·¥å…·é€²è¡Œåˆ¤æ–·ï¼›"
                    "å®‰å…¨å› OKï¼›éœ€è¦æ””æˆªæ™‚å› BLOCK: <åŸå› >ï¼ˆåƒ…æ­¤å…©ç¨®ï¼‰ã€‚"
                ),
                expected_output="OK æˆ– BLOCK: <åŸå› >",
                agent=guard,
            )
            guard_res = (
                Crew(agents=[guard], tasks=[guard_task], verbose=False).kickoff().raw
                or ""
            ).strip()
        except Exception:
            guard_res = ModelGuardrailTool()._run(full_text)

            # åªä¿ç•™æ””æˆªèˆ‡å¦
        is_block = guard_res.startswith("BLOCK:")
        block_reason = guard_res[6:].strip() if is_block else ""

        # ç”¢ç”Ÿæœ€çµ‚å›è¦†ï¼šå„ªå…ˆç”¨ CrewAIï¼›å¤±æ•—å‰‡ fallback OpenAI + Milvus æŸ¥è©¢
        try:
            care = agent_manager.get_health_agent(user_id)

            # P0-3: BLOCK åˆ†æ”¯ç›´æ¥è·³éè¨˜æ†¶/RAG æª¢ç´¢ï¼Œç¯€çœæˆæœ¬
            if is_block:
                ctx = ""  # ä¸æª¢ç´¢è¨˜æ†¶
            else:
                ctx = build_prompt_from_redis(user_id, k=6, current_input=full_text)

            task = Task(
                description=(
                    f"{ctx}\n\nä½¿ç”¨è€…è¼¸å…¥ï¼š{full_text}\n"
                    "è«‹ä»¥ã€åœ‹æ°‘å­«å¥³ã€å£å»å›è¦†ï¼Œéµå®ˆã€å›è¦†é¢¨æ ¼è¦å‰‡ã€‘ï¼šç¦æ­¢åˆ—é»ã€ä¸è¦ç”¨æ•¸å­—æˆ–ç¬¦è™Ÿé–‹é ­ã€é¿å…å­¸è¡“å¼æ‘˜è¦ï¼›å°èªæ··ä¸­æ–‡ã€è‡ªç„¶èŠå¤©æ„Ÿã€‚"
                    + (
                        "\nã€å®‰å…¨æ”¿ç­–â€”å¿…é ˆå©‰æ‹’ã€‘æ­¤è¼¸å…¥è¢«å®‰å…¨æª¢æŸ¥åˆ¤å®šç‚ºè¶…å‡ºèƒ½åŠ›ç¯„åœï¼ˆä¾‹å¦‚é•æ³•ã€æˆäººå…§å®¹ã€é†«ç™‚/ç”¨è—¥/åŠ‘é‡/è¨ºæ–·ç­‰å…·é«”æŒ‡ç¤ºï¼‰ã€‚"
                        "è«‹ç›´æ¥å©‰æ‹’ï¼Œ**ä¸è¦**æä¾›ä»»ä½•å…·é«”æ–¹æ¡ˆã€è¨ºæ–·æˆ–åŠ‘é‡ï¼Œä¹Ÿ**ä¸è¦**ç¡¬çµ¦æ›¿ä»£ä½œæ³•ã€‚"
                        "åƒ…å¯çµ¦ä¸€èˆ¬å±¤ç´šçš„å®‰å…¨æé†’ï¼ˆå¦‚ï¼šé¼“å‹µè«®è©¢åˆæ ¼é†«å¸«/è—¥å¸«ï¼‰èˆ‡æƒ…ç·’å®‰æ’«çš„ä¸€å…©å¥è©±ã€‚"
                        if is_block
                        else "\nã€æ­£å¸¸å›è¦†ã€‘è‹¥å…§å®¹å±¬ä¸€èˆ¬è¡›æ•™/æ—¥å¸¸é—œæ‡·ï¼Œç°¡çŸ­å›æ‡‰ä¸¦å¯çµ¦ 1â€“2 å€‹å°æ­¥é©Ÿå»ºè­°ã€‚"
                    )
                ),
                expected_output="å°èªé¢¨æ ¼çš„æº«æš–é—œæ‡·å›è¦†ï¼Œå¿…è¦æ™‚ä½¿ç”¨å·¥å…·ã€‚",
                agent=care,
            )
            res = Crew(agents=[care], tasks=[task], verbose=False).kickoff().raw or ""
        except Exception:
            client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            model = os.getenv("MODEL_NAME", "gpt-4o-mini")
            if is_block:
                # P0-3: BLOCK åˆ†æ”¯è·³éè¨˜æ†¶/RAG æª¢ç´¢
                sys = "ä½ æ˜¯æœƒè¬›å°èªçš„å¥åº·é™ªä¼´è€…ã€‚ç•¶è¼¸å…¥è¢«åˆ¤ç‚ºè¶…å‡ºèƒ½åŠ›ç¯„åœæ™‚ï¼Œå¿…é ˆå©‰æ‹’ä¸”ä¸å¯æä¾›å…·é«”æ–¹æ¡ˆ/è¨ºæ–·/åŠ‘é‡ï¼Œåªèƒ½ä¸€èˆ¬æ€§æé†’å°±é†«ã€‚èªæ°£æº«æš–ã€ä¸åˆ—é»ã€‚"
                user_msg = f"æ­¤è¼¸å…¥è¢«åˆ¤ç‚ºè¶…å‡ºèƒ½åŠ›ç¯„åœï¼ˆ{block_reason or 'å®‰å…¨é¢¨éšª'}ï¼‰ã€‚è«‹ç”¨å°èªæº«æŸ”å©‰æ‹’ï¼Œä¸æä¾›ä»»ä½•å…·é«”å»ºè­°æˆ–æ›¿ä»£ä½œæ³•ï¼Œåªåšä¸€èˆ¬å®‰å…¨æé†’èˆ‡æƒ…ç·’å®‰æ’« 1â€“2 å¥ã€‚"
                res_obj = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": sys},
                        {"role": "user", "content": user_msg},
                    ],
                    temperature=0.2,
                )
                res = (res_obj.choices[0].message.content or "").strip()
            else:
                ctx = build_prompt_from_redis(user_id, k=6, current_input=full_text)
                qa = SearchMilvusTool()._run(full_text)
                sys = "ä½ æ˜¯æœƒè¬›å°èªçš„å¥åº·é™ªä¼´è€…ï¼Œèªæ°£æº«æš–å‹™å¯¦ï¼Œé¿å…é†«ç™‚è¨ºæ–·èˆ‡åŠ‘é‡æŒ‡ç¤ºã€‚å¿…è¦æ™‚æé†’å°±é†«ã€‚"
                prompt = (
                    f"{ctx}\n\nç›¸é—œè³‡æ–™ï¼ˆå¯èƒ½ç©ºï¼‰ï¼š\n{qa}\n\n"
                    f"ä½¿ç”¨è€…è¼¸å…¥ï¼š{full_text}\nè«‹ä»¥å°èªé¢¨æ ¼å›è¦†ï¼›çµå°¾çµ¦ä¸€æ®µæº«æš–é¼“å‹µã€‚"
                )
                res_obj = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": sys},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.5,
                )
                res = (res_obj.choices[0].message.content or "").strip()
        # 5) çµæœå¿«å– + è½æ­·å²
        set_audio_result(user_id, audio_id, res)
        log_session(user_id, full_text, res)
        return res

    finally:
        release_audio_lock(lock_id)
